{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qB_7i8RU9hvg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import glob\n",
    "# import h5py\n",
    "# import shutil\n",
    "# import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mimg\n",
    "# import imgaug.augmenters as iaa\n",
    "# from os import listdir, makedirs, getcwd, remove\n",
    "# from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "# from PIL import Image\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "# from skimage.io import imread\n",
    "# from skimage.transform import resize\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D, BatchNormalization\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "# from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.python.keras import layers, models, optimizers, callbacks\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WGqS6Kbn99pU"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Set the seed for hash based operations in python\n",
    "# os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# # Set the numpy seed\n",
    "# np.random.seed(111)\n",
    "\n",
    "\n",
    "# # Set the random seed in tensorflow at graph level\n",
    "# tf.random.set_seed(111)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "# # Assuming you already have a TensorFlow session 'sess'\n",
    "# sess = tf.compat.v1.Session()\n",
    "\n",
    "# # Set the session\n",
    "# set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cM_hK1sj-ka9"
   },
   "outputs": [],
   "source": [
    "# data_dir = Path('/content/drive/MyDrive/DR')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = Path('Final')\n",
    "\n",
    "# # Path to validation directory\n",
    "# val_dir = data_dir / 'val'\n",
    "\n",
    "# # Path to test directory\n",
    "# test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NHxIWpsu_q1y"
   },
   "outputs": [],
   "source": [
    "dir_arr = np.empty((5,), dtype=Path)\n",
    "for i in range(0,5):\n",
    "  dir_arr[i] = train_dir / f'{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uW-Xp6NmAoRm"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(0,5):\n",
    "  for img in os.listdir(dir_arr[i]):\n",
    "      train_data.append((dir_arr[i] / img,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fx-GWVvD_FX0",
    "outputId": "6e15f115-246d-4f64-a84a-aaca3f7296a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final\\0\\1313_left.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final\\4\\23648_right.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final\\1\\1999_left_augmented_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Final\\1\\25236_left_augmented_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Final\\1\\13209_left_augmented_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                image  label\n",
       "0              Final\\0\\1313_left.jpeg      0\n",
       "1            Final\\4\\23648_right.jpeg      4\n",
       "2   Final\\1\\1999_left_augmented_1.jpg      1\n",
       "3  Final\\1\\25236_left_augmented_1.jpg      1\n",
       "4  Final\\1\\13209_left_augmented_0.jpg      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "TujqWSdvCM4E",
    "outputId": "1a5f92b1-31f5-41ba-aef8-fc26bca884d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final\\4\\23648_right.jpeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Final\\4\\16565_left_augmented_0.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Final\\4\\22520_left_augmented_0.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Final\\4\\13669_right_augmented_5.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Final\\4\\19588_left_augmented_2.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30951</th>\n",
       "      <td>Final\\4\\7853_right_augmented_0.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30953</th>\n",
       "      <td>Final\\4\\10193_right_augmented_0_f.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30962</th>\n",
       "      <td>Final\\4\\37958_left_augmented_2.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30983</th>\n",
       "      <td>Final\\4\\30723_left_augmented_3.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30984</th>\n",
       "      <td>Final\\4\\41761_left_augmented_4.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image  label\n",
       "1                   Final\\4\\23648_right.jpeg      4\n",
       "7         Final\\4\\16565_left_augmented_0.jpg      4\n",
       "8         Final\\4\\22520_left_augmented_0.jpg      4\n",
       "13       Final\\4\\13669_right_augmented_5.jpg      4\n",
       "24        Final\\4\\19588_left_augmented_2.jpg      4\n",
       "...                                      ...    ...\n",
       "30951     Final\\4\\7853_right_augmented_0.jpg      4\n",
       "30953  Final\\4\\10193_right_augmented_0_f.jpg      4\n",
       "30962     Final\\4\\37958_left_augmented_2.jpg      4\n",
       "30983     Final\\4\\30723_left_augmented_3.jpg      4\n",
       "30984     Final\\4\\41761_left_augmented_4.jpg      4\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['label'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "id": "SU0Wsc01FEkd",
    "outputId": "ad0641bc-53e4-4874-b5e9-c1fe8338173c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAALMCAYAAABkEhrBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVa0lEQVR4nO3de1hVZf7//9cG5CC4ASkgRZFyUtHU1FIyzygZdtIaa8xMLUeHbJTfqDnjqGmjZZmHybSDqX3KtKZ08hyeM/FEMaml2eSpFDANUFSO6/eHF+vrjkMiyD3g83Fd67pgrfe613ttdjO+rnuvezssy7IEAAAAADDCzXQDAAAAAHA9I5QBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQD+53Xu3FkOh0MTJ0403YpR58+f19///nc1adJEPj4+cjgccjgcSk5ONt0aAKAcCGUAUEVNnDjR/kd5zZo1deLEiRJrjxw5Ytdu3ry58ppEherbt69eeOEFHThwQA6HQyEhIQoJCVGNGjVMtwYAKAdCGQBUAxcuXNDzzz9vug1cQwcOHNDKlSslSUuXLtX58+eVkpKilJQUNW3a1HB3AIDyIJQBQDXxzjvv6LvvvjPdBq6RvXv3SpKCgoL0+9//3nA3AICKRCgDgCquXr16at68ufLy8vTXv/7VdDu4Rs6fPy9J8vPzM9wJAKCiEcoAoIpzc3PT1KlTJUkff/yxdu3aVabzL3/e7MiRIyXWNWjQQA6HQwsXLiz1/KNHj+rpp59W/fr15e3trVtuuUXjxo1TVlaWfc6+ffv0+OOPq169evL29tbvfvc7vfDCC8rNzf3NfnNycvTiiy+qefPm8vX1VWBgoLp37641a9b85rn79u3TkCFD9Lvf/U41a9aUn5+fmjdvrr/97W/6+eefiz2n8Nm9zp07S7r0Gvfo0UPBwcFyc3Mr8+IjFy9e1MyZM3XXXXcpMDBQ3t7eCg8P1xNPPFHsgh2F13/yySclSUePHrVf78v3l8XOnTs1cOBANWzYUDVr1pTT6VRkZKQGDRqkdevWFanfsWOHxowZow4dOig8PFze3t4KCAhQu3bt9NJLL+ncuXMlXuvChQt65ZVXFBUVpcDAQNWoUUM33nijIiMjNWDAAH388cclnns1f6/C++vXr58iIiLk7e0tX19fhYeHq1OnTpo8ebJ+/PHHsr1gAHCtWQCAKmnChAmWJCs8PNyyLMvq1KmTJcnq0qVLkdrDhw9bkixJ1qZNm0o8dvjw4RKvFx4ebkmyFixYUOL5H3/8sRUQEGBJspxOp+Xu7m4f69Chg5WTk2OtXLnSqlmzpiXJ8vf3txwOh13Tt2/fYq9deG9jx461OnToYEmyPDw87GsVbhMmTCix/5deeslyc3Oza2vWrGl5enrav990003Wl19+WeLr3KlTJys+Pt6SZDkcDiswMNByd3cv9Zq/9uOPP1rNmjWzr1mjRg3L39/f/t3Nzc2aPXu2yzkvv/yyFRISYjmdTrsmJCTE3p599tkrvn5eXp717LPPurxmvr6+VmBgoP138Pf3L3Le5fU1a9a0AgMDXfZFRkZaqampRc7LzMy0WrRoYdc5HA4rICDA8vDwsPcVvn9/7Wr/XgsXLnR5T3l5edmvXeH26/cwAJhGKAOAKurXoSwxMdH+R+eaNWtcaisrlAUEBFjdunWz9u/fb1mWZZ0/f96aPXu2Hc7GjRtn+fv7W3379rWOHDliWZZlnT171vrb3/5mj5GQkFDk2oWhzN/f3/Ly8rLmzZtnXbhwwbIsyzp27Jj18MMP2+f/+9//LnL+22+/bUmy/Pz8rH/84x/WyZMnLcu6FFL27Nljde3a1ZJkhYWFWWfPni32dfbz87MkWWPGjLHS0tIsy7Ksixcv2vfxW/Ly8qy2bdva9/Hee+9Z2dnZlmVZ1n//+1+rV69ednBZvXp1kfMXLFhQaoi5EqNHj7Zfp0GDBlkHDx60j6Wnp1vLly8vNhjfd9991tKlS+3XzbIu/W0/+eQTq1GjRpYk66GHHipy3uTJky1JVu3ata2PP/7YunjxomVZlpWfn2/99NNP1rvvvms9/fTTRc672r9XVlaWVatWLUuS9fjjj1vff/+9fezcuXPWnj17rFGjRlmrVq26ilcPAK4dQhkAVFG/DmWWZVkPPfSQJclq2bKlVVBQYO+vrFDWtGlT+x/el+vfv79d0717d5feChXOgA0ePLjIscJQJsmaP39+keP5+flWx44d7R4ul5mZac+orV27tth7y83NtVq3bm1JsmbMmOFyrPB1lmTFx8cXe/6VWLJkiT3OunXriu2hMLQ1a9asyPHyhrKDBw/aM0+jR4++qjGK8+OPP1peXl6Ww+Gwjh496nKsZ8+eliRrypQpVzxeef5eO3futGf/cnNzr+p+AMAEnikDgGpkypQpcnd3V3Jysj744INKv/7IkSPl5eVVZH9MTIz983PPPSeHw1Fizddff13i+PXq1dPAgQOL7Hdzc9O4ceMkSfv377dXKpQuPQOWnp6u22+/3aWPy3l4eOixxx6TpGKfqSq8xpgxY0rs7bcsXbpUkhQVFaUePXoU28OECRMkXXqW6vJ7qAiLFi1SQUGBgoKCKvTrE+rWrasWLVrIsixt377d5VhAQIAk6eTJk1c8Xnn+XoXXy8nJ0enTp8twFwBglofpBgAAFadx48YaOHCg3n77bf3973/XI488UqlfLHznnXcWuz8kJMT++Y477ii15pdffilx/M6dOxcb6CSpQ4cO8vDwUF5envbs2aPbbrtNkvTFF19Ikr799luFhoaWOPaFCxckXVpIozgNGzZUcHBwief/lj179kiSoqOjS6zp0qWL3N3dlZ+f73IPFaEwMHXv3l3e3t5lOregoEBLlizRkiVLlJycrFOnTunixYtF6n69gEavXr30wQcf6LXXXtOpU6fUt29f3X333brhhhtKvFZ5/l633HKLGjdurAMHDqht27YaNmyYYmJidNttt8nd3b1M9wwAlYmZMgCoZiZOnCgfHx/98MMPmjdvXqVeu1atWsXu9/DwuOKa0lZgrFu3bonHvL29FRQUJElKS0uz9584cULSpVUPU1NTS9wyMzMl/b+l53+tPIHs8p5+6x4KA8vl91ARUlJSJEnh4eFlOu/8+fOKjo5Wv379tGLFCh0/flwFBQWqXbu2QkJCFBISYgf/y1fYlKQ//OEP+vOf/yyHw6ElS5booYce0o033qjf/e53iouLU1JSUpHrlefv5e7uriVLligiIkJHjx7Vc889p9tvv11Op1Pdu3fX3LlzS/z7AoBJhDIAqGbq1q2r4cOHS5JeeOGFUpcrvx7k5+dLkvr27Svr0rPUpW4lfS1AVZ9pKWmG8bf84x//0KZNm+Tj46MZM2bo6NGjunjxok6fPq2UlBSlpKSobdu2kiTLsoqcP3PmTB08eFBTpkxRz549FRAQoO+//16vv/662rRpoxEjRrjUl/fv1aJFCx04cEAff/yxhgwZombNmunChQtav369/vSnP6lx48YV/tFQACgvQhkAVEPPPfecAgMDlZaWpunTp5dae/ksVnEfSSuUkZFRYf1drZ9++qnEY9nZ2fZzRJfPahV+BK6kjyVWlsKeSvuOrMKwc3l9Rbna12HJkiWSpPHjx2vEiBGqX79+kYBXOAtXkoYNG2rs2LFavXq1Tp8+rcTERD344IOSpFmzZunTTz8td5+X8/T0VO/evfXGG29o7969OnXqlObNm6fatWvr+PHjGjBgwFWPDQDXAqEMAKqhwMBAPffcc5Kk6dOn69SpU6XWFjp+/HixNd99953S09MrtMersWXLlmJnYyTp888/V15eniSpTZs29v727dtLkpKSksq04ERFK+xpw4YNJdZs3rzZvoeSnr27WnfddZckKSEhodTw/WuF74nbb7+92ONHjhzR999/f8Xjubm5qV27dvrXv/6l+vXr2z0VuhZ/r6CgIP3xj3/USy+9JEn66quvWAgEwP8UQhkAVFPDhw9XWFiYzp49q8mTJ5dY5+vrq1tuuUXSpZXvivOPf/zjmvRYVseOHdOiRYuK7C8oKNCUKVMkSZGRkS4LZDzyyCMKCAhQbm6u4uPjSwx1heNcq/D56KOPSpISExP12WefFTmel5enSZMmSZKaNWumZs2aVej1n3zySbm7u+v06dP2Ko9Xwt/fX5L0n//8p9jjheG/ONnZ2SUec3d3l6enp6RLQa1Qef5epV1Pknx8fOyfL78mAJjG/yIBQDXl4+OjiRMnSpJWrFhRam3h8uLvvPOOXn/9dXtlu+PHj+upp57S0qVLVbNmzWva75Xw9/fXsGHD9NZbb9mzPcePH9djjz2mTZs2Sbr0HN3lAgICNHPmTEmXPooXGxurnTt3qqCgQNKlf9h/++23mj59upo2baqVK1dek9779OljP3v1+9//XosXL7YXNTl8+LD69OmjxMRESdK0adMq/PoNGzbUqFGj7PGfeuopHTp0yD6emZmppUuX6qGHHnI575577pF06XX95JNP7Jm8w4cP6w9/+IM+/PBDl9nWy7Vt21bPPvusNm/e7LIIyIkTJzR8+HB7hu3ee++1j5Xn77VkyRK1b99eb7zxhn744Qd7f35+vtatW2cHyKioqBJ7BgAjKvE70QAAFai4L4/+tby8PKtx48b2lxarmC+PtizLOnv2rBUZGWnXuLm52V/gW6NGDeuDDz64oi+PLunLpzdt2mTXlKS0L0cu/PLosWPHWnfffbfdV2BgoMu9jRs3rsTx586da3l6etq1Xl5eVlBQkFWjRg2XMd577z2X8wpf506dOpU49pX68ccfraZNm9rX8vT0tF/nwtd91qxZxZ5b3i+PtqxL74e4uDiX+/Xz87MCAwMth8NhSbL8/f1dzjly5IgVEhJi13t4eFj+/v7271OmTLH/PhMmTHA5t/A9I8lyOBxWQECA5evr63L9kSNHFtvr1fy9Cl+jX59T+KXZkqw6depY33777VW/hgBwLTBTBgDVmLu7u/2xvtL4+flp27Ztio+PV0REhDw8PFSjRg179qbwo3emeXp6asOGDZoyZYoaNWqk7Oxs+fv7q1u3blq1alWpH9McOnSoDh48qL/85S9q0aKFvLy8lJ6eLj8/P7Vp00bDhw9XQkKCPWt4LdStW1d79uzRq6++qnbt2snHx0fnz59XvXr11L9/fyUlJenZZ5+9Ztd3d3fXa6+9pm3btqlfv36qX7++cnNzZVmWIiMjNXjw4CIfYQ0PD9eePXs0ePBg1alTR9Klpft79eqldevWaezYsSVeb8mSJXr++efVrVs3RUREKCcnR7m5uQoPD1ffvn21YcMGvfrqq8WeezV/r/vvv1/vvvuuBg4cqBYtWsjf318ZGRmqVauW7rzzTk2ePFn79+9X48aNK+DVBICK47CsUj6sDQAAAAC4ppgpAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAZ5mG6gOikoKNCJEydUq1YtORwO0+0AAAAAMMSyLJ09e1Z16tSRm1vpc2GEsgp04sQJ1atXz3QbAAAAAP5HHD9+XGFhYaXWEMoqUK1atSRdeuGdTqfhbgAAAACYkpmZqXr16tkZoTSEsgpU+JFFp9NJKAMAAABwRY81sdAHAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwqEqEsgYNGsjhcBTZ4uLiJEkXL15UXFycgoKC5Ofnpz59+ig1NdVljGPHjik2NlY1a9ZUcHCwRo0apby8PJeazZs3q1WrVvLy8lLDhg21cOHCyrpFAAAAANepKhHKdu/erZMnT9pbQkKCJOmRRx6RJI0cOVIrVqzQRx99pC1btujEiRPq3bu3fX5+fr5iY2OVk5Oj7du3a9GiRVq4cKHGjx9v1xw+fFixsbHq0qWLkpOTNWLECD311FNat25d5d4sAAAAgOuKw7Isy3QTZTVixAitXLlShw4dUmZmpm688UYtXrxYDz/8sCTpwIEDatKkiRITE9WuXTutWbNGvXr10okTJxQSEiJJmjdvnsaMGaNTp07J09NTY8aM0apVq7Rv3z77Oo8++qjS09O1du3aK+orMzNT/v7+ysjIkNPprPgbBwAAAFAllCUbVImZssvl5OTovffe06BBg+RwOJSUlKTc3FxFR0fbNY0bN1b9+vWVmJgoSUpMTNRtt91mBzJJiomJUWZmpvbv32/XXD5GYU3hGMXJzs5WZmamywYAAAAAZeFhuoGyWr58udLT0/Xkk09KklJSUuTp6amAgACXupCQEKWkpNg1lweywuOFx0qryczM1IULF+Tj41Okl6lTp+r555+viNuytR71boWOh/9tSS8/YezavNeuLybfawAAoHRVbqZs/vz56tmzp+rUqWO6FY0dO1YZGRn2dvz4cdMtAQAAAKhiqtRM2dGjR7V+/Xp98skn9r7Q0FDl5OQoPT3dZbYsNTVVoaGhds2uXbtcxipcnfHyml+v2Jiamiqn01nsLJkkeXl5ycvLq9z3BQAAAOD6VaVmyhYsWKDg4GDFxsba+1q3bq0aNWpow4YN9r6DBw/q2LFjioqKkiRFRUVp7969SktLs2sSEhLkdDoVGRlp11w+RmFN4RgAAAAAcC1UmVBWUFCgBQsWaMCAAfLw+H8TfP7+/ho8eLDi4+O1adMmJSUlaeDAgYqKilK7du0kST169FBkZKT69++v//znP1q3bp3GjRunuLg4e6Zr6NCh+uGHHzR69GgdOHBAr7/+uj788EONHDnSyP0CAAAAuD5UmY8vrl+/XseOHdOgQYOKHJsxY4bc3NzUp08fZWdnKyYmRq+//rp93N3dXStXrtSwYcMUFRUlX19fDRgwQJMmTbJrIiIitGrVKo0cOVKzZs1SWFiY3n77bcXExFTK/QEAAAC4PlXJ7yn7X1UR31PGinjXF1ZfRGVh9UUAACpXtf6eMgAAAACoTghlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAg6pMKPvpp5/0+OOPKygoSD4+Prrtttu0Z88e+7hlWRo/frxuuukm+fj4KDo6WocOHXIZ48yZM+rXr5+cTqcCAgI0ePBgnTt3zqXm66+/VocOHeTt7a169epp2rRplXJ/AAAAAK5PVSKU/fLLL2rfvr1q1KihNWvW6JtvvtH06dMVGBho10ybNk2zZ8/WvHnztHPnTvn6+iomJkYXL160a/r166f9+/crISFBK1eu1NatWzVkyBD7eGZmpnr06KHw8HAlJSXp5Zdf1sSJE/Xmm29W6v0CAAAAuH54mG7gSrz00kuqV6+eFixYYO+LiIiwf7YsSzNnztS4ceP0wAMPSJLeffddhYSEaPny5Xr00Uf17bffau3atdq9e7fatGkjSfrnP/+pe++9V6+88orq1Kmj999/Xzk5OXrnnXfk6emppk2bKjk5Wa+++qpLeAMAAACAilIlZso+/fRTtWnTRo888oiCg4N1++2366233rKPHz58WCkpKYqOjrb3+fv7q23btkpMTJQkJSYmKiAgwA5kkhQdHS03Nzft3LnTrunYsaM8PT3tmpiYGB08eFC//PJLkb6ys7OVmZnpsgEAAABAWVSJmbIffvhBc+fOVXx8vP76179q9+7devbZZ+Xp6akBAwYoJSVFkhQSEuJyXkhIiH0sJSVFwcHBLsc9PDxUu3Ztl5rLZ+AuHzMlJcXl45KSNHXqVD3//PMVd6MAUA21HvWu6RZQiZJefsLYtXmvXV9MvteAilYlZsoKCgrUqlUrTZkyRbfffruGDBmip59+WvPmzTPa19ixY5WRkWFvx48fN9oPAAAAgKqnSoSym266SZGRkS77mjRpomPHjkmSQkNDJUmpqakuNampqfax0NBQpaWluRzPy8vTmTNnXGqKG+Pya1zOy8tLTqfTZQMAAACAsqgSoax9+/Y6ePCgy77vvvtO4eHhki4t+hEaGqoNGzbYxzMzM7Vz505FRUVJkqKiopSenq6kpCS7ZuPGjSooKFDbtm3tmq1btyo3N9euSUhIUKNGjYp8dBEAAAAAKkKVCGUjR47Ujh07NGXKFH3//fdavHix3nzzTcXFxUmSHA6HRowYoRdeeEGffvqp9u7dqyeeeEJ16tTRgw8+KOnSzNo999yjp59+Wrt27dIXX3yhZ555Ro8++qjq1KkjSfrDH/4gT09PDR48WPv379fSpUs1a9YsxcfHm7p1AAAAANVclVjo44477tCyZcs0duxYTZo0SREREZo5c6b69etn14wePVpZWVkaMmSI0tPTdffdd2vt2rXy9va2a95//30988wz6tatm9zc3NSnTx/Nnj3bPu7v76/PPvtMcXFxat26tW644QaNHz+e5fABAAAAXDNVIpRJUq9evdSrV68SjzscDk2aNEmTJk0qsaZ27dpavHhxqddp3ry5Pv/886vuEwAAAADKokp8fBEAAAAAqitCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwKAqEcomTpwoh8PhsjVu3Ng+fvHiRcXFxSkoKEh+fn7q06ePUlNTXcY4duyYYmNjVbNmTQUHB2vUqFHKy8tzqdm8ebNatWolLy8vNWzYUAsXLqyM2wMAAABwHasSoUySmjZtqpMnT9rbtm3b7GMjR47UihUr9NFHH2nLli06ceKEevfubR/Pz89XbGyscnJytH37di1atEgLFy7U+PHj7ZrDhw8rNjZWXbp0UXJyskaMGKGnnnpK69atq9T7BAAAAHB98TDdwJXy8PBQaGhokf0ZGRmaP3++Fi9erK5du0qSFixYoCZNmmjHjh1q166dPvvsM33zzTdav369QkJC1LJlS02ePFljxozRxIkT5enpqXnz5ikiIkLTp0+XJDVp0kTbtm3TjBkzFBMTU6n3CgAAAOD6UWVmyg4dOqQ6dero5ptvVr9+/XTs2DFJUlJSknJzcxUdHW3XNm7cWPXr11diYqIkKTExUbfddptCQkLsmpiYGGVmZmr//v12zeVjFNYUjlGc7OxsZWZmumwAAAAAUBZVYqasbdu2WrhwoRo1aqSTJ0/q+eefV4cOHbRv3z6lpKTI09NTAQEBLueEhIQoJSVFkpSSkuISyAqPFx4rrSYzM1MXLlyQj49Pkb6mTp2q559/vqJuEwAAAFVA61Hvmm4BlSjp5Seu+TWqRCjr2bOn/XPz5s3Vtm1bhYeH68MPPyw2LFWWsWPHKj4+3v49MzNT9erVM9YPAAAAgKqnynx88XIBAQG69dZb9f333ys0NFQ5OTlKT093qUlNTbWfQQsNDS2yGmPh779V43Q6Swx+Xl5ecjqdLhsAAAAAlEWVDGXnzp3Tf//7X910001q3bq1atSooQ0bNtjHDx48qGPHjikqKkqSFBUVpb179yotLc2uSUhIkNPpVGRkpF1z+RiFNYVjAAAAAMC1UCVC2V/+8hdt2bJFR44c0fbt2/XQQw/J3d1djz32mPz9/TV48GDFx8dr06ZNSkpK0sCBAxUVFaV27dpJknr06KHIyEj1799f//nPf7Ru3TqNGzdOcXFx8vLykiQNHTpUP/zwg0aPHq0DBw7o9ddf14cffqiRI0eavHUAAAAA1VyVeKbsxx9/1GOPPabTp0/rxhtv1N13360dO3boxhtvlCTNmDFDbm5u6tOnj7KzsxUTE6PXX3/dPt/d3V0rV67UsGHDFBUVJV9fXw0YMECTJk2yayIiIrRq1SqNHDlSs2bNUlhYmN5++22WwwcAAABwTVWJULZkyZJSj3t7e2vOnDmaM2dOiTXh4eFavXp1qeN07txZX3311VX1CAAAAABXo0p8fBEAAAAAqitCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBB5QplkyZN0quvvnrF9bNnz9akSZPKc0kAAAAAqFbKFcomTpyoV1555YrrZ8yYoeeff748lwQAAACAaoWPLwIAAACAQZUays6cOSNvb+9yjfHiiy/K4XBoxIgR9r6LFy8qLi5OQUFB8vPzU58+fZSamupy3rFjxxQbG6uaNWsqODhYo0aNUl5enkvN5s2b1apVK3l5ealhw4ZauHBhuXoFAAAAgN9SaaHso48+0tmzZ1W/fv2rHmP37t1644031Lx5c5f9I0eO1IoVK/TRRx9py5YtOnHihHr37m0fz8/PV2xsrHJycrR9+3YtWrRICxcu1Pjx4+2aw4cPKzY2Vl26dFFycrJGjBihp556SuvWrbvqfgEAAADgt3iUpXjWrFmaNWuWy75Tp07p5ptvLvEcy7KUnp6uzMxMORwOxcbGXlWj586dU79+/fTWW2/phRdesPdnZGRo/vz5Wrx4sbp27SpJWrBggZo0aaIdO3aoXbt2+uyzz/TNN99o/fr1CgkJUcuWLTV58mSNGTNGEydOlKenp+bNm6eIiAhNnz5dktSkSRNt27ZNM2bMUExMTLE9ZWdnKzs72/49MzPzqu4NAAAAwPWrTDNl6enpOnLkiL1Jl2ahLt/36+3o0aPKyMiQZVnq2rWry+xUWcTFxSk2NlbR0dEu+5OSkpSbm+uyv3Hjxqpfv74SExMlSYmJibrtttsUEhJi18TExCgzM1P79++3a349dkxMjD1GcaZOnSp/f397q1ev3lXdGwAAAIDrV5lmyh588EE1aNBA0qUZsEGDBsnf318zZ84s8Rw3Nzc5nU41a9ZMt9xyy1U1uWTJEn355ZfavXt3kWMpKSny9PRUQECAy/6QkBClpKTYNZcHssLjhcdKq8nMzNSFCxfk4+NT5Npjx45VfHy8/XtmZibBDAAAAECZlCmUtWjRQi1atLB/HzRokHx8fDRgwIAKb6zQ8ePH9ec//1kJCQnlXiSkonl5ecnLy8t0GwAAAACqsHIt9FFQUKATJ05UVC/FSkpKUlpamlq1aiUPDw95eHhoy5Ytmj17tjw8PBQSEqKcnBylp6e7nJeamqrQ0FBJUmhoaJHVGAt//60ap9NZ7CwZAAAAAFSE//nvKevWrZv27t2r5ORke2vTpo369etn/1yjRg1t2LDBPufgwYM6duyYoqKiJElRUVHau3ev0tLS7JqEhAQ5nU5FRkbaNZePUVhTOAYAAAAAXAtl+vhiaQoKCnTo0CGdOXNGubm5pdZ27NjxisetVauWmjVr5rLP19dXQUFB9v7BgwcrPj5etWvXltPp1PDhwxUVFaV27dpJknr06KHIyEj1799f06ZNU0pKisaNG6e4uDj744dDhw7Va6+9ptGjR2vQoEHauHGjPvzwQ61ataosLwMAAAAAlEm5Q9nJkyc1duxY/etf/9KFCxd+s97hcBT50ubymjFjhtzc3NSnTx9lZ2crJiZGr7/+un3c3d1dK1eu1LBhwxQVFSVfX18NGDBAkyZNsmsiIiK0atUqjRw5UrNmzVJYWJjefvvtEpfDBwAAAICKUK5QduLECbVt21YnTpyQZVlXdM6V1pVm8+bNLr97e3trzpw5mjNnTonnhIeHa/Xq1aWO27lzZ3311Vfl7g8AAAAArlS5nimbOHGifvrpJ/n5+Wn27Nk6evSocnNzVVBQUOoGAAAAALikXDNla9askcPh0Pz58/Xwww9XVE8AAAAAcN0o10zZqVOn5OHhoQcffLCC2gEAAACA60u5QllwcLB8fHzk4VFhizgCAAAAwHWlXKEsOjpaZ8+e1aFDhyqqHwAAAAC4rpQrlP31r3+Vr6+vxowZU1H9AAAAAMB1pVyhrGHDhvr000+1ZcsWde/eXZs2bVJWVlZF9QYAAAAA1V65HgZzd3e3f964caM2btz4m+dciy+PBgAAAICqqlyhrCK+CBoAAAAArmflCmWbNm2qqD4AAAAA4LpUrlDWqVOniuoDAAAAAK5L5VroAwAAAABQPoQyAAAAADCoXB9f3Lp161Wd17Fjx/JcFgAAAACqjXKFss6dO8vhcJTpHJbEBwAAAID/p1yhTCr7svgsow8AAAAA/0+5nikrKCgodUtPT9e6devUqVMnBQUFacuWLSooKKio3gEAAACgyrumC304nU51795dGzdu1F133aX7779fhw8fvpaXBAAAAIAqpVJWX3Q4HJo2bZoyMjI0efLkyrgkAAAAAFQJlbYkfqNGjeR0OpWQkFBZlwQAAACA/3nlXujjSuXm5urChQu6ePFiZV0SAAAAAP7nVdpM2fLly5Wbm6vg4ODKuiQAAAAA/M+7pjNlOTk5On78uD7++GNNmTJFDodDPXv2vJaXBAAAAIAqpVyhzN3d/YprLctS3bp1NWHChPJcEgAAAACqlXJ9fNGyrCvavL299fjjj2vHjh2qU6dORfUOAAAAAFVeuWbKNm3aVPrgHh4KDAzUrbfeKg+PSltTBAAAAACqjHIlpU6dOlVUHwAAAABwXaq01RcBAAAAAEVV+GcKjx49qrS0NElScHCwwsPDK/oSAAAAAFBtVMhM2cmTJ/Xss88qODhYN998s9q1a6d27drp5ptvVnBwsEaMGKGTJ09WxKUAAAAAoFopdyj74osv1Lx5c82ZM0c///xzkZUXf/75Z/3zn/9UixYttH379oroGQAAAACqjXJ9fDEtLU3333+/fvnlFzmdTg0dOlTdu3dXWFiYJOnHH3/U+vXr9cYbb+jnn3/W/fffr2+++UbBwcEV0jwAAAAAVHXlCmXTp0/XL7/8osaNGyshIUF169Z1Od6oUSN169ZNw4cPV3R0tA4ePKhXX31VL774YrmaBgAAAIDqolwfX1y1apUcDofeeuutIoHscnXq1NFbb70ly7K0cuXK8lwSAAAAAKqVcoWyI0eOyNfXV+3bt//N2vbt28vX11dHjx4tzyUBAAAAoFqp9O8psyyrsi8JAAAAAP+zyhXKGjRooKysLO3YseM3axMTE5WVlaUGDRqU55IAAAAAUK2UK5T17NlTlmVpyJAhOnXqVIl1aWlpGjJkiBwOh+69997yXBIAAAAAqpVyrb74l7/8RfPnz9f+/fvVpEkTDRs2TN26dbMX/fjxxx+1YcMGvfHGGzp9+rQCAgL0//1//1+FNA4AAAAA1UG5QllISIiWLVumhx56SGfOnNGUKVM0ZcqUInWWZSkgIEDLly9XSEhIeS4JAAAAANVKuRf66NSpk77++mv98Y9/VGBgoCzLctkCAwM1bNgw7d27Vx07dqyIngEAAACg2ijXTFmhsLAwzZ07V3PnztXhw4eVlpYmSQoODlZERERFXAIAAAAAqqUyh7K8vDydP39ekuR0Ooscj4iIKBLEMjMzJUm+vr5yd3e/mj4BAAAAoFoq88cXH330UQUGBurJJ5+84nMGDRpU5nMAAAAA4HpQplC2f/9+ffLJJ3I6nXrnnXeu+Ly33npLTqdTH3zwgQ4dOlTmJgEAAACguipTKHv//fclSX/6058UEBBwxecFBgZq+PDhKigo0HvvvVemBgEAAACgOitTKPv888/lcDjUp0+fMl+od+/ekqTNmzeX+VwAAAAAqK7KFMq+++47ubm56fbbby/zhZo3by43NzcdOHCgzOcCAAAAQHVVplCWnp6ugIAAORyOsl/IzU0BAQHKyMgo87kAAAAAUF2VKZTVrFlTZ8+eveqLnTt3Tj4+Pld9PgAAAABUN2UKZcHBwcrNzdV///vfMl/ov//9r3JychQcHFzmcwEAAACguipTKGvXrp0k6ZNPPinzhT7++GNJUtu2bct8LgAAAABUV2UKZb169ZJlWXr55Zd18uTJKz7vxIkTeuWVV+RwONSrV68yNwkAAAAA1VWZQlmfPn30u9/9TqdPn1ZMTMwVfYzx+++/1z333KOff/5ZDRs21COPPHLVzQIAAABAdVOmUObm5qZFixbJ09NT+/fvV/PmzfXHP/5Ra9asUUpKinJycpSTk6OUlBStWbNGQ4YMUcuWLbVv3z55eXlp4cKFV7VyIwAAAABUVx5lPaFdu3b68MMP1b9/f2VmZurtt9/W22+/XWK9ZVny8/PT//3f/ykqKqpczQIAAABAdVOmmbJC9913n/bs2aNHHnlEDodDlmUVuzkcDj3yyCNKSkrSAw88UNG9AwAAAECVV+aZskINGzbU0qVLlZaWpk2bNmn//v06ffq0JCkoKEhNmzZVly5dWAIfAAAAAEpx1aGsUHBwsPr27VsRvQAAAADAdeeqPr4IAAAAAKgYhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGFQlQtncuXPVvHlzOZ1OOZ1ORUVFac2aNfbxixcvKi4uTkFBQfLz81OfPn2UmprqMsaxY8cUGxurmjVrKjg4WKNGjVJeXp5LzebNm9WqVSt5eXmpYcOGWrhwYWXcHgAAAIDrWJUIZWFhYXrxxReVlJSkPXv2qGvXrnrggQe0f/9+SdLIkSO1YsUKffTRR9qyZYtOnDih3r172+fn5+crNjZWOTk52r59uxYtWqSFCxdq/Pjxds3hw4cVGxurLl26KDk5WSNGjNBTTz2ldevWVfr9AgAAALh+eJhu4Ercd999Lr//4x//0Ny5c7Vjxw6FhYVp/vz5Wrx4sbp27SpJWrBggZo0aaIdO3aoXbt2+uyzz/TNN99o/fr1CgkJUcuWLTV58mSNGTNGEydOlKenp+bNm6eIiAhNnz5dktSkSRNt27ZNM2bMUExMTKXfMwAAAIDrQ5WYKbtcfn6+lixZoqysLEVFRSkpKUm5ubmKjo62axo3bqz69esrMTFRkpSYmKjbbrtNISEhdk1MTIwyMzPt2bbExESXMQprCscoTnZ2tjIzM102AAAAACiLKhPK9u7dKz8/P3l5eWno0KFatmyZIiMjlZKSIk9PTwUEBLjUh4SEKCUlRZKUkpLiEsgKjxceK60mMzNTFy5cKLanqVOnyt/f397q1atXEbcKAAAA4DpSZUJZo0aNlJycrJ07d2rYsGEaMGCAvvnmG6M9jR07VhkZGfZ2/Phxo/0AAAAAqHqqxDNlkuTp6amGDRtKklq3bq3du3dr1qxZ6tu3r3JycpSenu4yW5aamqrQ0FBJUmhoqHbt2uUyXuHqjJfX/HrFxtTUVDmdTvn4+BTbk5eXl7y8vCrk/gAAAABcn6rMTNmvFRQUKDs7W61bt1aNGjW0YcMG+9jBgwd17NgxRUVFSZKioqK0d+9epaWl2TUJCQlyOp2KjIy0ay4fo7CmcAwAAAAAuBaqxEzZ2LFj1bNnT9WvX19nz57V4sWLtXnzZq1bt07+/v4aPHiw4uPjVbt2bTmdTg0fPlxRUVFq166dJKlHjx6KjIxU//79NW3aNKWkpGjcuHGKi4uzZ7qGDh2q1157TaNHj9agQYO0ceNGffjhh1q1apXJWwcAAABQzVWJUJaWlqYnnnhCJ0+elL+/v5o3b65169ape/fukqQZM2bIzc1Nffr0UXZ2tmJiYvT666/b57u7u2vlypUaNmyYoqKi5OvrqwEDBmjSpEl2TUREhFatWqWRI0dq1qxZCgsL09tvv81y+AAAAACuqSoRyubPn1/qcW9vb82ZM0dz5swpsSY8PFyrV68udZzOnTvrq6++uqoeAQAAAOBqVNlnygAAAACgOiCUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADKoSoWzq1Km64447VKtWLQUHB+vBBx/UwYMHXWouXryouLg4BQUFyc/PT3369FFqaqpLzbFjxxQbG6uaNWsqODhYo0aNUl5enkvN5s2b1apVK3l5ealhw4ZauHDhtb49AAAAANexKhHKtmzZori4OO3YsUMJCQnKzc1Vjx49lJWVZdeMHDlSK1as0EcffaQtW7boxIkT6t27t308Pz9fsbGxysnJ0fbt27Vo0SItXLhQ48ePt2sOHz6s2NhYdenSRcnJyRoxYoSeeuoprVu3rlLvFwAAAMD1w8N0A1di7dq1Lr8vXLhQwcHBSkpKUseOHZWRkaH58+dr8eLF6tq1qyRpwYIFatKkiXbs2KF27drps88+0zfffKP169crJCRELVu21OTJkzVmzBhNnDhRnp6emjdvniIiIjR9+nRJUpMmTbRt2zbNmDFDMTExlX7fAAAAAKq/KjFT9msZGRmSpNq1a0uSkpKSlJubq+joaLumcePGql+/vhITEyVJiYmJuu222xQSEmLXxMTEKDMzU/v377drLh+jsKZwjF/Lzs5WZmamywYAAAAAZVHlQllBQYFGjBih9u3bq1mzZpKklJQUeXp6KiAgwKU2JCREKSkpds3lgazweOGx0moyMzN14cKFIr1MnTpV/v7+9lavXr0KuUcAAAAA148qF8ri4uK0b98+LVmyxHQrGjt2rDIyMuzt+PHjplsCAAAAUMVUiWfKCj3zzDNauXKltm7dqrCwMHt/aGiocnJylJ6e7jJblpqaqtDQULtm165dLuMVrs54ec2vV2xMTU2V0+mUj49PkX68vLzk5eVVIfcGAAAA4PpUJWbKLMvSM888o2XLlmnjxo2KiIhwOd66dWvVqFFDGzZssPcdPHhQx44dU1RUlCQpKipKe/fuVVpaml2TkJAgp9OpyMhIu+byMQprCscAAAAAgIpWJWbK4uLitHjxYv373/9WrVq17GfA/P395ePjI39/fw0ePFjx8fGqXbu2nE6nhg8frqioKLVr106S1KNHD0VGRqp///6aNm2aUlJSNG7cOMXFxdmzXUOHDtVrr72m0aNHa9CgQdq4caM+/PBDrVq1yti9AwAAAKjeqsRM2dy5c5WRkaHOnTvrpptusrelS5faNTNmzFCvXr3Up08fdezYUaGhofrkk0/s4+7u7lq5cqXc3d0VFRWlxx9/XE888YQmTZpk10RERGjVqlVKSEhQixYtNH36dL399tsshw8AAADgmqkSM2WWZf1mjbe3t+bMmaM5c+aUWBMeHq7Vq1eXOk7nzp311VdflblHAAAAALgaVWKmDAAAAACqK0IZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAoCoRyrZu3ar77rtPderUkcPh0PLly12OW5al8ePH66abbpKPj4+io6N16NAhl5ozZ86oX79+cjqdCggI0ODBg3Xu3DmXmq+//lodOnSQt7e36tWrp2nTpl3rWwMAAABwnasSoSwrK0stWrTQnDlzij0+bdo0zZ49W/PmzdPOnTvl6+urmJgYXbx40a7p16+f9u/fr4SEBK1cuVJbt27VkCFD7OOZmZnq0aOHwsPDlZSUpJdfflkTJ07Um2++ec3vDwAAAMD1y8N0A1eiZ8+e6tmzZ7HHLMvSzJkzNW7cOD3wwAOSpHfffVchISFavny5Hn30UX377bdau3atdu/erTZt2kiS/vnPf+ree+/VK6+8ojp16uj9999XTk6O3nnnHXl6eqpp06ZKTk7Wq6++6hLeAAAAAKAiVYmZstIcPnxYKSkpio6Otvf5+/urbdu2SkxMlCQlJiYqICDADmSSFB0dLTc3N+3cudOu6dixozw9Pe2amJgYHTx4UL/88kux187OzlZmZqbLBgAAAABlUeVDWUpKiiQpJCTEZX9ISIh9LCUlRcHBwS7HPTw8VLt2bZea4sa4/Bq/NnXqVPn7+9tbvXr1yn9DAAAAAK4rVT6UmTR27FhlZGTY2/Hjx023BAAAAKCKqfKhLDQ0VJKUmprqsj81NdU+FhoaqrS0NJfjeXl5OnPmjEtNcWNcfo1f8/LyktPpdNkAAAAAoCyqfCiLiIhQaGioNmzYYO/LzMzUzp07FRUVJUmKiopSenq6kpKS7JqNGzeqoKBAbdu2tWu2bt2q3NxcuyYhIUGNGjVSYGBgJd0NAAAAgOtNlQhl586dU3JyspKTkyVdWtwjOTlZx44dk8Ph0IgRI/TCCy/o008/1d69e/XEE0+oTp06evDBByVJTZo00T333KOnn35au3bt0hdffKFnnnlGjz76qOrUqSNJ+sMf/iBPT08NHjxY+/fv19KlSzVr1izFx8cbumsAAAAA14MqsST+nj171KVLF/v3wqA0YMAALVy4UKNHj1ZWVpaGDBmi9PR03X333Vq7dq28vb3tc95//30988wz6tatm9zc3NSnTx/Nnj3bPu7v76/PPvtMcXFxat26tW644QaNHz+e5fABAAAAXFNVIpR17txZlmWVeNzhcGjSpEmaNGlSiTW1a9fW4sWLS71O8+bN9fnnn191nwAAAABQVlXi44sAAAAAUF0RygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRygAAAADAIEIZAAAAABhEKAMAAAAAgwhlAAAAAGAQoQwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGEQoAwAAAACDCGUAAAAAYBChDAAAAAAMIpQBAAAAgEGEMgAAAAAwiFAGAAAAAAYRyooxZ84cNWjQQN7e3mrbtq127dpluiUAAAAA1RSh7FeWLl2q+Ph4TZgwQV9++aVatGihmJgYpaWlmW4NAAAAQDVEKPuVV199VU8//bQGDhyoyMhIzZs3TzVr1tQ777xjujUAAAAA1ZCH6Qb+l+Tk5CgpKUljx46197m5uSk6OlqJiYlF6rOzs5WdnW3/npGRIUnKzMy86h7ysy9c9bmoesrzXikv3mvXF95rqCy811BZeK+hslzte63wPMuyfrPWYV1J1XXixIkTqlu3rrZv366oqCh7/+jRo7Vlyxbt3LnTpX7ixIl6/vnnK7tNAAAAAFXE8ePHFRYWVmoNM2XlMHbsWMXHx9u/FxQU6MyZMwoKCpLD4TDYWdWSmZmpevXq6fjx43I6nabbQTXGew2VhfcaKgvvNVQW3mtlZ1mWzp49qzp16vxmLaHsMjfccIPc3d2Vmprqsj81NVWhoaFF6r28vOTl5eWyLyAg4Fq2WK05nU7+I0el4L2GysJ7DZWF9xoqC++1svH397+iOhb6uIynp6dat26tDRs22PsKCgq0YcMGl48zAgAAAEBFYabsV+Lj4zVgwAC1adNGd955p2bOnKmsrCwNHDjQdGsAAAAAqiFC2a/07dtXp06d0vjx45WSkqKWLVtq7dq1CgkJMd1ateXl5aUJEyYU+SgoUNF4r6Gy8F5DZeG9hsrCe+3aYvVFAAAAADCIZ8oAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMRs2ZM0cNGjSQt7e32rZtq127dpluCdXQ1q1bdd9996lOnTpyOBxavny56ZZQTU2dOlV33HGHatWqpeDgYD344IM6ePCg6bZQDc2dO1fNmze3v8g3KipKa9asMd0WqrkXX3xRDodDI0aMMN1KtUMogzFLly5VfHy8JkyYoC+//FItWrRQTEyM0tLSTLeGaiYrK0stWrTQnDlzTLeCam7Lli2Ki4vTjh07lJCQoNzcXPXo0UNZWVmmW0M1ExYWphdffFFJSUnas2ePunbtqgceeED79+833Rqqqd27d+uNN95Q8+bNTbdSLbEkPoxp27at7rjjDr322muSpIKCAtWrV0/Dhw/Xc889Z7g7VFcOh0PLli3Tgw8+aLoVXAdOnTql4OBgbdmyRR07djTdDqq52rVr6+WXX9bgwYNNt4Jq5ty5c2rVqpVef/11vfDCC2rZsqVmzpxpuq1qhZkyGJGTk6OkpCRFR0fb+9zc3BQdHa3ExESDnQFAxcnIyJB06R/LwLWSn5+vJUuWKCsrS1FRUabbQTUUFxen2NhYl3+3oWJ5mG4A16eff/5Z+fn5CgkJcdkfEhKiAwcOGOoKACpOQUGBRowYofbt26tZs2am20E1tHfvXkVFRenixYvy8/PTsmXLFBkZabotVDNLlizRl19+qd27d5tupVojlAEAcA3ExcVp37592rZtm+lWUE01atRIycnJysjI0L/+9S8NGDBAW7ZsIZihwhw/flx//vOflZCQIG9vb9PtVGuEMhhxww03yN3dXampqS77U1NTFRoaaqgrAKgYzzzzjFauXKmtW7cqLCzMdDuopjw9PdWwYUNJUuvWrbV7927NmjVLb7zxhuHOUF0kJSUpLS1NrVq1svfl5+dr69ateu2115SdnS13d3eDHVYfPFMGIzw9PdW6dWtt2LDB3ldQUKANGzbweXgAVZZlWXrmmWe0bNkybdy4UREREaZbwnWkoKBA2dnZpttANdKtWzft3btXycnJ9tamTRv169dPycnJBLIKxEwZjImPj9eAAQPUpk0b3XnnnZo5c6aysrI0cOBA062hmjl37py+//57+/fDhw8rOTlZtWvXVv369Q12huomLi5Oixcv1r///W/VqlVLKSkpkiR/f3/5+PgY7g7VydixY9WzZ0/Vr19fZ8+e1eLFi7V582atW7fOdGuoRmrVqlXkmVhfX18FBQXxrGwFI5TBmL59++rUqVMaP368UlJS1LJlS61du7bI4h9Aee3Zs0ddunSxf4+Pj5ckDRgwQAsXLjTUFaqjuXPnSpI6d+7ssn/BggV68sknK78hVFtpaWl64okndPLkSfn7+6t58+Zat26dunfvbro1AFeB7ykDAAAAAIN4pgwAAAAADCKUAQAAAIBBhDIAAAAAMIhQBgAAAAAGEcoAAAAAwCBCGQAAAAAYRCgDAAAAAIMIZQAAAABgEKEMAAAAAAzyMN0AAOD6kp+fr48//lgrV67Ujh07lJaWpvPnzysgIEC33nqrOnTooH79+qlZs2amW72mli9fruTkZLVs2VIPPvig6XYAAAY5LMuyTDcBALg+7NixQwMGDNB3331n76tRo4Zq1aql9PR0FRQU2Pt79+6tDz74QJ6eniZaveaefPJJLVq0SAMGDNDChQtNtwMAMIiPLwIAKsWKFSvUuXNnfffddwoKCtLUqVP13XffKScnR6dPn1ZOTo52796t5557Tk6nU5988onOnz9vum0AAK45Pr4IALjmDh06pMcff1zZ2dmKjIzUunXrFBYW5lLj7u6uNm3aqE2bNho1apQGDRpkqFsAACoXM2UAgGtu3LhxyszMlLe3t5YtW1YkkP1a7dq1tXz5cvn7+9v7CgoKtGHDBj377LNq166dwsLC5OnpqaCgIHXq1Enz5s1Tbm5uiWP+8ssvGj9+vFq1aiWn0ylPT0+FhoaqefPmGjp0qDZs2FDiuV988YUef/xxhYeHy9vbW/7+/rrzzjv10ksv6dy5c2V6LTZv3iyHw6FFixZJkhYtWiSHw+Gybd68WQcOHLB/37VrV6lj9u/fXw6HQ507d7b3HTlyxD7/yJEjOnTokJ588kmFhYXJy8tL9evX19ChQ3XixIlSxy4oKND777+ve++9VyEhIfL09NSNN96oHj166IMPPhBPQQBABbAAALiGUlJSLDc3N0uSNXjw4Kse5/Dhw5Yke/Pz87P8/f1d9nXo0ME6f/58kXOPHz9u1a9f365zc3OzAgMDLXd3d3tfp06dipyXn59vPfvss0Wue/l5jRo1so4cOXLF9/HFF19YISEhlre3tyXJ8vb2tkJCQly2L774wrIsy+rUqdNvvm5nzpyxx3r//feLfb2WLFli1apVy+7fx8fHPla7dm0rKSmp2LFPnz5tdezY0eX+f/2a33///VZ2dvYV3z8AoChmygAA19SmTZvsBTweeuihqx7Hw8ND/fr106effqrTp0/r7NmzSk9P19mzZ7VgwQLVqVNHn3/+uf72t78VOXfixIk6duyYGjRooPXr1ysnJ0dnzpxRdna2jhw5orlz56pdu3ZFzpswYYJmz56t4OBgzZkzx77uhQsXtGnTJt1+++06ePCgevfu7bJISWnuuusupaSkqG/fvpKkvn37KiUlxWW76667JEnDhg2TJC1ZskRnz54tdrz33ntPFy9eVFBQkPr06VNszR//+EdFRERo586dOnv2rLKysrRu3TrVr19fZ86c0UMPPVRk/Pz8fPXu3Vtbt25Vy5YttWLFCmVlZSk9PV3nzp3TokWLFBwcrE8//VRjxoy5onsHAJTAdCoEAFRv48aNs2dVfvrpp2t2nd27d1uSLF9fX+vChQsux5o0aWJJshYvXnzF4x0+fNhyd3e3fHx8rOTk5GJrMjMzrbCwMEuStWzZsjL1O2DAAEuSNWDAgBJrcnJyrODgYEuSNW/evGJrbrvtNkuSFR8fX6T/wtc9KCjISk1NLXLuN998Y3l6elqSrGnTprkce/fddy1JVuPGja309PRir71nzx7L4XBYnp6exY4PALgyzJQBAK6p06dP2z/Xrl37ml2nTZs2Cg4OVlZWlpKTk12OBQQESJJOnjx5xeMtXLhQ+fn5uueee9SiRYtia2rVqmV/x9i6deuupu1S1ahRQ4MHD5Ykvfnmm0WO79ixQ3v37pUkDRkypMRxhg4dquDg4CL7mzRpoocffljSpdm4y82fP1/Spdm6y5/tu1zr1q3VtGlT5eTkaNOmTVdwRwCA4hDKAABVRk5OjubNm6cePXqoTp068vLyclkgIy0tTZL0448/upzXq1cvSdJzzz2nIUOGaO3atcrMzCz1Wl988YUk6bPPPlNoaGiJ24IFCyRJR48erejblXQpbLm5uenLL7/Ul19+6XLsrbfekiR16tRJjRo1KnGMrl27/uaxr7/+2l4oJT8/Xzt27JB06aOfpd3/wYMHJV27+weA6wFL4gMArqmgoCD75zNnzqhOnTpXNU5aWpqio6PtmSFJ8vb21g033CB3d3dJ0qlTp1RQUKCsrCyXc0eNGqX//Oc/+vDDD/XWW2/prbfeksPhUNOmTXXPPffoqaeeKhJqClclzMrKKjJeca7Vd6o1aNBAMTExWrNmjd58803NmzdPkpSZmamlS5dKuvTMWGnq1q37m8fy8vJ05swZhYSE2M/bSZdWrbwSfKccAFw9ZsoAANdU06ZN7Z+/+uqrqx5n5MiR2rt3r4KCgvTOO+/o5MmTunDhgk6dOmUvkFEY+KxfLdNeo0YNLV26VMnJyRo/fry6du2qmjVrat++fXrllVfUtGlTTZ8+3eWc/Px8SdKYMWNkWdZvbps3b77qe/sthQt+LF682A6IhT8HBQWpd+/eFXq9wnuXpDVr1lzR/U+cOLFCewCA6wmhDABwTXXp0kVubpf+72bZsmVXNUZubq4++eQTSdJrr72mgQMHKjQ01KUmPz9fP//8c6njtGjRQs8//7w2bNig9PR0rV+/Xh07dlR+fr49m1aocPz/hY/l3XvvvapXr57Onj1rP/tV+NHFJ598Ul5eXqWe/9NPP/3mMQ8PD/uZv6CgIHl4XPowzf/C/QNAdUcoAwBcUyEhIfZS7YsXL9Z33313xecWznidOnVKFy9elCTdfvvtxdZu27bNrrkSHh4e6tatm1atWiUvLy9ZlqX169fbx9u3by9JWr9+fZnGvVKFQfXXs3rFcXd3txfyePPNN12eLyttgY9CpS3CUXisefPmqlGjhqRLM4t33nmnJGnFihW/OT4AoHwIZQCAa+6FF16Qn5+fLly4oN69e5c6cyNdeo6pT58+ysjIkCQ5nU45HA5JcpnNKpSXl1fs95MVKnw+qjheXl72M2mFQUmSBg0aJA8PD/3888+aMGFCqf3m5OTo3Llzpdb8mtPplCSlp6dfUf3gwYPl4eGhXbt2aeTIkZIuLfBx6623/ua58+bNK3YW8eDBg/rXv/4lSfb3phUqDHurV6/W6tWrSx3/zJkzV3QPAIDiEcoAANfcrbfeqv/7v/+Tp6en9u/fr5YtW+qll17S999/b9fk5+frq6++0vjx43XzzTfbH1eUJD8/P3vmKj4+Xhs3brS/rHnfvn269957tWfPHvn6+hZ7/fDwcI0dO1Y7duxwCWjff/+9+vXrp/Pnz8vNzU0xMTH2sVtuuUV///vfJUnTpk3TE088oX379tnH8/LylJycrEmTJqlhw4ZFluH/Lc2aNZMkff755zpw4MBv1t9000164IEHJElbt26V9NsLfBTKzc1V9+7dtXv3bkmyZwVjYmKUnZ2tevXqaejQoS7nPP7444qOjpZlWXrooYf0wgsv2IufSJcWQNm0aZPi4uJ08803X1EfAIASVN5XogEArnfbtm2zGjZsaH+psSTL09PTql27tuXm5mbvczgc1mOPPWbl5OTY5+7Zs8fy9fW1a7y8vKxatWpZkiwPDw/r3XfftcLDwy1J1oIFC1yue/n13NzcrMDAQMvb29vlejNmzCjSb0FBgfX3v//dcjgcdq2Pj48VFBRkubu7u4y7bdu2Mr0WZ86csW688Ub7/BtuuMEKDw+3wsPDrcTExGLPWb9+vcsXQl+8eLHE8S//8uglS5bYr5Wfn59Vs2ZN+1hAQIC1e/fuYsfIyMiwevXq5XKfTqfTCggIcHlNPDw8ynTvAABXzJQBACpN+/btdeDAAX3wwQfq16+fGjZsKG9vb509e1a1a9fW3Xffrb/97W/69ttvtXjxYvsZJ+nSFxXv2rVLv//973XDDTeooKBAtWrV0u9//3tt375d/fv3L/G6n332mcaOHasOHTqoXr16unDhgiSpYcOGGjhwoHbv3q0RI0YUOc/hcGjSpEn6+uuv9ac//UlNmjSRu7u7MjIyFBgYqLvuukujRo3S9u3b7Zm8KxUYGKitW7fq0UcfVd26dZWRkaGjR4/q6NGjJT7D1rVrV3sxjitZ4KNQ27ZttWfPHj3xxBPy9/dXXl6e6tatq6efflp79+5VmzZtij3P6XRqxYoVWr16tfr27av69esrOztb58+fV926ddWjRw9NnTrV/q4yAMDVcVjWFTxhDAAAjEtKSrID1MGDB0t9nuzIkSOKiIiQJB0+fFgNGjSojBYBAFeBmTIAAKqIf/7zn5IuzZhdyQIfAICqgVAGAEAVsHr1ar333nuSpL/85S+GuwEAVCQP0w0AAIDi/fjjj7r77rt1/vx5nTp1SpLUq1cv9ezZ03BnAICKRCgDAOB/VF5eno4ePSqHw6GwsDA9/PDDmjx5sum2AAAVjIU+AAAAAMAgnikDAAAAAIMIZQAAAABgEKEMAAAAAAwilAEAAACAQYQyAAAAADCIUAYAAAAABhHKAAAAAMAgQhkAAAAAGPT/AxYRr0W7Uyv7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cases_count = train_data['label'].value_counts()\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=18)\n",
    "plt.xlabel('Case type', fontsize=18)\n",
    "plt.ylabel('Count', fontsize=18)\n",
    "plt.xticks(range(len(cases_count.index)), [str(i) for i in range(0,5)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "def res(img,wid=256):\n",
    "  height, width = img.shape[:2]\n",
    "  aspect_ratio = width / height\n",
    "  desired_height = int(wid / aspect_ratio)\n",
    "\n",
    "  # Resize the image while maintaining the aspect ratio\n",
    "  resized_img = cv2.resize(img, (wid, desired_height))\n",
    "  return resized_img\n",
    "\n",
    "def samp(pt):\n",
    "# Read the image\n",
    "    img = cv2.imread(pt)\n",
    "    print(type(img))\n",
    "    # Calculate the new height to maintain the aspect ratio\n",
    "\n",
    "\n",
    "    # Display the resized image using cv2_imshow\n",
    "    cv2.imshow('wd',res(img))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() \n",
    "\n",
    "\n",
    "def rad(image):\n",
    "  # Calculate the current radius (assuming a square image)\n",
    "  current_radius = min(image.shape[0], image.shape[1]) / 2\n",
    "\n",
    "  # Set the target radius\n",
    "  target_radius = 300.0\n",
    "\n",
    "  # Calculate the scaling factor\n",
    "  scaling_factor = target_radius / current_radius\n",
    "\n",
    "  # Resize the image with the calculated scaling factor\n",
    "  resized_image = cv2.resize(image, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "  # Display the original and resized images\n",
    "  return resized_image\n",
    "\n",
    "def filt2(pt):# Load the given image (I1)\n",
    "  I1 = cv2.imread(pt)\n",
    "  I1 = rad(I1)\n",
    "  # Load the original image (I2) to be blurred\n",
    "  # original_I2 = cv2.imread(pt)\n",
    "  # original_I2 = rad(original_I2)\n",
    "  # Apply Gaussian blur to I2\n",
    "  I2 = cv2.GaussianBlur(I1, (25,25), 18)\n",
    "\n",
    "\n",
    "\n",
    "  # Perform the operation I = 4I1 - 4I2 + 128\n",
    "  result_image = 4 * I1 - 4 * I2 + 128\n",
    "\n",
    "  # Clip the result to ensure pixel values are within the valid range [0, 255]\n",
    "  result_image = np.clip(result_image, 0, 255).astype(np.uint8)\n",
    "  I2 = res(I2)\n",
    "  I1 = res(I1)\n",
    "  # result_image = res(result_image)\n",
    "  # original_I2 = res(original_I2)\n",
    "  # # cv2_imshow(I1)\n",
    "  # # cv2_imshow(I2)\n",
    "  # # Create a 2x2 subplot grid\n",
    "  # plt.subplot(2, 2, 1), plt.imshow(cv2.cvtColor(I1, cv2.COLOR_BGR2RGB)), plt.title('I1')\n",
    "  # plt.subplot(2, 2, 2), plt.imshow(cv2.cvtColor(I2, cv2.COLOR_BGR2RGB)), plt.title('I2')\n",
    "  # # plt.subplot(2, 2, 3), plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)), plt.title('Result Image')\n",
    "  # plt.subplot(2, 2, 4), plt.imshow(cv2.cvtColor(original_I2, cv2.COLOR_BGR2RGB)), plt.title('Original I2 (Blurred)')\n",
    "  # # Adjust layout for better visualization\n",
    "  # plt.tight_layout()\n",
    "  # # Show the plot\n",
    "  # plt.show()\n",
    "  return result_image\n",
    "\n",
    "def cut(image):\n",
    "  # Read the image\n",
    "\n",
    "    # Get the center coordinates of the image\n",
    "  center_x, center_y = image.shape[1] // 2, image.shape[0] // 2\n",
    "\n",
    "  # Define the size of the crop\n",
    "  crop_size = 256\n",
    "\n",
    "  # Calculate the region to crop around the center while maintaining aspect ratio\n",
    "  start_x = max(0, center_x - crop_size // 2)\n",
    "  start_y = max(0, center_y - crop_size // 2)\n",
    "  end_x = min(image.shape[1], center_x + crop_size // 2)\n",
    "  end_y = min(image.shape[0], center_y + crop_size // 2)\n",
    "\n",
    "  # Crop the image\n",
    "  cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "  # Resize the cropped image to exactly 256 x 256 pixels\n",
    "  # cropped_image = cv2.resize(cropped_image, (256, 256))\n",
    "\n",
    "  # Save the cropped image\n",
    "  return cropped_image\n",
    "\n",
    "def cut_after_filt(img):\n",
    "  height, width = img.shape[:2]\n",
    "  aspect_ratio = width / height\n",
    "  desired_width = int(256 * aspect_ratio)\n",
    "  resized_img = cv2.resize(img, (desired_width, 256))\n",
    "  return cut(resized_img)\n",
    "\n",
    "def pre_pro(img):\n",
    "  return cut_after_filt(filt2(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of validation examples:  (250, 224, 224, 3)\n",
      "Total number of labels: (250, 5)\n"
     ]
    }
   ],
   "source": [
    "valid_data = []\n",
    "valid_labels = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    for img in os.listdir(f'Val/{i}'):\n",
    "        # img = pre_pro(f'Val/{i}'+'/'+img)\n",
    "        img = cv2.imread(f'Val/{i}'+'/'+img)\n",
    "        img = cv2.resize(img,(224,224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)/255.\n",
    "        label = to_categorical(0, num_classes=5)\n",
    "        valid_data.append(img)\n",
    "        valid_labels.append(label)\n",
    "\n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid_data)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data.shape)\n",
    "print(\"Total number of labels:\", valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Tr9QqouUFei-"
   },
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "\n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 256, 256, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,5), dtype=np.float32)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    # Initialize a counter\n",
    "    i =0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "\n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=5)\n",
    "            # read the image and resize\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (256,256))\n",
    "\n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "\n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "            count+=1\n",
    "\n",
    "            if count==batch_size-1:\n",
    "                break\n",
    "\n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "\n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import VGG16\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # Load pre-trained VGG16 model without the top (fully connected) layers\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SuO5mqv2JW2G"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(256,256,3), name='ImageInput')\n",
    "    x = Conv2D(64, (7,7), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (5,5), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((3,3), name='pool1')(x)\n",
    "\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    # x = BatchNormalization(name='bn3')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    # x = BatchNormalization(name='bn4')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    # x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    # x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    # x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(5, activation='softmax', name='fc3')(x)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnC6d2YjKyk2",
    "outputId": "a1b99fd5-e87a-44f9-b398-479180cdcc65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ImageInput (InputLayer)     [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " Conv1_1 (Conv2D)            (None, 256, 256, 64)      9472      \n",
      "                                                                 \n",
      " Conv1_2 (Conv2D)            (None, 256, 256, 64)      102464    \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 85, 85, 64)        0         \n",
      "                                                                 \n",
      " Conv2_1 (SeparableConv2D)   (None, 85, 85, 128)       8896      \n",
      "                                                                 \n",
      " Conv2_2 (SeparableConv2D)   (None, 85, 85, 128)       17664     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 42, 42, 128)       0         \n",
      "                                                                 \n",
      " Conv3_1 (SeparableConv2D)   (None, 42, 42, 256)       34176     \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 42, 42, 256)       1024      \n",
      "                                                                 \n",
      " Conv3_2 (SeparableConv2D)   (None, 42, 42, 256)       68096     \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 42, 42, 256)       1024      \n",
      "                                                                 \n",
      " Conv3_3 (SeparableConv2D)   (None, 42, 42, 256)       68096     \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 21, 21, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 112896)            0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 1024)              115606528 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 512)               524800    \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116444805 (444.20 MB)\n",
      "Trainable params: 116443781 (444.20 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  build_model()\n",
    "# for i in [1,2,4,5]:\n",
    "#     model.layers[i] = base_model.layers[i]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QEKbKwmsLcAM"
   },
   "outputs": [],
   "source": [
    "# opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHuDVakXL-Z-",
    "outputId": "3364d949-a19a-4eae-93cb-329712176c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps: 620\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "nb_epochs = 30\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Number of training steps: {}\".format(nb_train_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKjCgU8eMMp1",
    "outputId": "fcb2b92e-1c4f-45b0-ce4a-5502614889de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "446/620 [====================>.........] - ETA: 29:00 - loss: 1.5848 - accuracy: 0.2286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_train_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchkpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_gen, epochs=nb_epochs,validation_data=(valid_data, valid_labels) ,steps_per_epoch=nb_train_steps,callbacks=[es, chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3952 - accuracy: 0.7960\n",
      "Loss on test set:  0.39523619413375854\n",
      "Accuracy on test set:  0.7960000038146973\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_score = model.evaluate(valid_data, valid_labels, batch_size=16)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
